{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import packages we need for data exploration.\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-30T15:31:54.634063Z","iopub.execute_input":"2022-06-30T15:31:54.635012Z","iopub.status.idle":"2022-06-30T15:31:54.643195Z","shell.execute_reply.started":"2022-06-30T15:31:54.634972Z","shell.execute_reply":"2022-06-30T15:31:54.642004Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"# Load the data into a pandas dataframe.\ndf = pd.read_csv(r\"../input/bengaluru-house-price-data/Bengaluru_House_Data.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:31:58.430668Z","iopub.execute_input":"2022-06-30T15:31:58.431435Z","iopub.status.idle":"2022-06-30T15:31:58.474228Z","shell.execute_reply.started":"2022-06-30T15:31:58.431396Z","shell.execute_reply":"2022-06-30T15:31:58.472975Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"#  rows, columns\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:31:59.431041Z","iopub.execute_input":"2022-06-30T15:31:59.431388Z","iopub.status.idle":"2022-06-30T15:31:59.437467Z","shell.execute_reply.started":"2022-06-30T15:31:59.431362Z","shell.execute_reply":"2022-06-30T15:31:59.436519Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# Number of houses in each area type. \ndf.groupby('area_type')['area_type'].agg('count')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:00.079338Z","iopub.execute_input":"2022-06-30T15:32:00.079970Z","iopub.status.idle":"2022-06-30T15:32:00.092347Z","shell.execute_reply.started":"2022-06-30T15:32:00.079936Z","shell.execute_reply":"2022-06-30T15:32:00.090981Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"Some columns seem to be redundant.\n(\"area_type columns\", \"availability\", \"society\" and \"balcony\") I'll drop these columns, but in best practice you should consult your real estate manager and discuss on how important these columns are in deciding the price of a house","metadata":{}},{"cell_type":"code","source":"# Get rid of unnecessary columns.\ndf1 = df.drop(['area_type', 'availability', 'society', 'balcony'], axis=1)\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:01.651758Z","iopub.execute_input":"2022-06-30T15:32:01.652392Z","iopub.status.idle":"2022-06-30T15:32:01.668421Z","shell.execute_reply.started":"2022-06-30T15:32:01.652359Z","shell.execute_reply":"2022-06-30T15:32:01.667195Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# A count of the null data points in each column.\ndf1.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:02.310960Z","iopub.execute_input":"2022-06-30T15:32:02.311373Z","iopub.status.idle":"2022-06-30T15:32:02.324852Z","shell.execute_reply.started":"2022-06-30T15:32:02.311342Z","shell.execute_reply":"2022-06-30T15:32:02.323248Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# Drop every row that has a null data point or perhaps, You can run any interpolation method \n# of your choice if you do not wish to lose data entries.\ndf2 = df1.dropna()\nprint(df2.shape)\ndf2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:07.360027Z","iopub.execute_input":"2022-06-30T15:32:07.360422Z","iopub.status.idle":"2022-06-30T15:32:07.377542Z","shell.execute_reply.started":"2022-06-30T15:32:07.360390Z","shell.execute_reply":"2022-06-30T15:32:07.376211Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"The values in the size columns are conflicting. Let's take a look at them.","metadata":{}},{"cell_type":"code","source":"df2['size'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:11.339552Z","iopub.execute_input":"2022-06-30T15:32:11.340519Z","iopub.status.idle":"2022-06-30T15:32:11.350120Z","shell.execute_reply.started":"2022-06-30T15:32:11.340475Z","shell.execute_reply":"2022-06-30T15:32:11.348879Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# I'll create a new column, that takes the number from size column, e.g '2 BHK' will be '2' in our new column.\ndf2['bhk'] = df2['size'].apply(lambda x: int(x.split(' ')[0]))\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:12.617824Z","iopub.execute_input":"2022-06-30T15:32:12.618205Z","iopub.status.idle":"2022-06-30T15:32:12.644381Z","shell.execute_reply.started":"2022-06-30T15:32:12.618175Z","shell.execute_reply":"2022-06-30T15:32:12.643157Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"df2.bhk.unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:13.810914Z","iopub.execute_input":"2022-06-30T15:32:13.811560Z","iopub.status.idle":"2022-06-30T15:32:13.819262Z","shell.execute_reply.started":"2022-06-30T15:32:13.811528Z","shell.execute_reply":"2022-06-30T15:32:13.817817Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# The entries in the dataset where bhk is > 20.\ndf2[df2.bhk>15]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:15.118754Z","iopub.execute_input":"2022-06-30T15:32:15.120262Z","iopub.status.idle":"2022-06-30T15:32:15.135959Z","shell.execute_reply.started":"2022-06-30T15:32:15.120136Z","shell.execute_reply":"2022-06-30T15:32:15.134629Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"The values in total_sqft column seem to be conflicting as well. Let's have a look.","metadata":{}},{"cell_type":"code","source":"df2.total_sqft.unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:17.690628Z","iopub.execute_input":"2022-06-30T15:32:17.691770Z","iopub.status.idle":"2022-06-30T15:32:17.701313Z","shell.execute_reply.started":"2022-06-30T15:32:17.691718Z","shell.execute_reply":"2022-06-30T15:32:17.699577Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"There are several types of data points in the said column. Like range values (0000-1111), and other <br>units of length measurement. We'd address that right away.","metadata":{}},{"cell_type":"code","source":"# This function takes x (total_sqft column) and convert each data point to a float, \n# and returns False if it's not feasible. \ndef convertToFloat(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:20.251128Z","iopub.execute_input":"2022-06-30T15:32:20.251524Z","iopub.status.idle":"2022-06-30T15:32:20.257366Z","shell.execute_reply.started":"2022-06-30T15:32:20.251494Z","shell.execute_reply":"2022-06-30T15:32:20.256483Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# The entries in the dataset where the total_sqft is not a float; using the (~).\ndf2[~df2['total_sqft'].apply(convertToFloat)]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:21.601883Z","iopub.execute_input":"2022-06-30T15:32:21.603252Z","iopub.status.idle":"2022-06-30T15:32:21.628292Z","shell.execute_reply.started":"2022-06-30T15:32:21.603181Z","shell.execute_reply":"2022-06-30T15:32:21.627052Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"A simple approach to address this matter is to take the mean average of the range numbers. <br>\n(a+b)/2","metadata":{}},{"cell_type":"code","source":"# This function takes x (total_sqft) and takes the float average of the range data points.\ndef convertRangeToFloat(x):\n    numbers = x.split(' - ')\n    if len(numbers)==2:\n        return (float(numbers[0]) + float(numbers[1]))/len(numbers)\n    try:\n        return float(x)\n    except:\n        return None # We return None here, if the value cannot be converted to float.","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:25.178658Z","iopub.execute_input":"2022-06-30T15:32:25.179114Z","iopub.status.idle":"2022-06-30T15:32:25.186190Z","shell.execute_reply.started":"2022-06-30T15:32:25.179082Z","shell.execute_reply":"2022-06-30T15:32:25.184563Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"convertRangeToFloat('2334 - 7890')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:26.431219Z","iopub.execute_input":"2022-06-30T15:32:26.431698Z","iopub.status.idle":"2022-06-30T15:32:26.438429Z","shell.execute_reply.started":"2022-06-30T15:32:26.431648Z","shell.execute_reply":"2022-06-30T15:32:26.436919Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# I'll create a new dataframe and apply the above function to the total_sqft column.\ndf3 = df2.copy()\ndf3.total_sqft = df3.total_sqft.apply(convertRangeToFloat)\ndf3.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:27.798856Z","iopub.execute_input":"2022-06-30T15:32:27.799260Z","iopub.status.idle":"2022-06-30T15:32:27.824300Z","shell.execute_reply.started":"2022-06-30T15:32:27.799230Z","shell.execute_reply":"2022-06-30T15:32:27.823276Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"# Entries in the 30th index.\ndf3.loc[30]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:30.450865Z","iopub.execute_input":"2022-06-30T15:32:30.451669Z","iopub.status.idle":"2022-06-30T15:32:30.464900Z","shell.execute_reply.started":"2022-06-30T15:32:30.451630Z","shell.execute_reply":"2022-06-30T15:32:30.463849Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# A little comparison of the function's ouput.\n(2100+2850)/2","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:32.170515Z","iopub.execute_input":"2022-06-30T15:32:32.170891Z","iopub.status.idle":"2022-06-30T15:32:32.177184Z","shell.execute_reply.started":"2022-06-30T15:32:32.170859Z","shell.execute_reply":"2022-06-30T15:32:32.176290Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"Perfect!","metadata":{}},{"cell_type":"code","source":"df3.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:35.370254Z","iopub.execute_input":"2022-06-30T15:32:35.371586Z","iopub.status.idle":"2022-06-30T15:32:35.388758Z","shell.execute_reply.started":"2022-06-30T15:32:35.371523Z","shell.execute_reply":"2022-06-30T15:32:35.386774Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"# A new column 'price per sqft'; the quotient of price/total_sqft.\ndf4 = df3.copy()\ndf4['price_per_sqft'] = df4['price']*100000/df4['total_sqft'] # I multiply the price by 100000; 1 lakh = 100000\ndf4.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:36.811008Z","iopub.execute_input":"2022-06-30T15:32:36.811378Z","iopub.status.idle":"2022-06-30T15:32:36.830290Z","shell.execute_reply.started":"2022-06-30T15:32:36.811349Z","shell.execute_reply":"2022-06-30T15:32:36.829068Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"This new column gives a general sense of the actual cost of a house and can be used in outlier<br>\nfiltering as it gives a clear relative comparison of each data entry. ","metadata":{}},{"cell_type":"code","source":"# Number of unique locations in the dataset.\nlen(df4.location.unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:39.331108Z","iopub.execute_input":"2022-06-30T15:32:39.331524Z","iopub.status.idle":"2022-06-30T15:32:39.339914Z","shell.execute_reply.started":"2022-06-30T15:32:39.331485Z","shell.execute_reply":"2022-06-30T15:32:39.339072Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"# Number of houses in each location.\ndf4.location = df4.location.apply(lambda x: x.strip())\n\nlocation_tally = df4.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_tally.head(30)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:40.631286Z","iopub.execute_input":"2022-06-30T15:32:40.632464Z","iopub.status.idle":"2022-06-30T15:32:40.650098Z","shell.execute_reply.started":"2022-06-30T15:32:40.632403Z","shell.execute_reply":"2022-06-30T15:32:40.648823Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"# Number of locations that have <= 10 houses in the dataset.\nlen(location_tally[location_tally<=10]) # This is a series so this type of syntax works.","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:41.911101Z","iopub.execute_input":"2022-06-30T15:32:41.911660Z","iopub.status.idle":"2022-06-30T15:32:41.920299Z","shell.execute_reply.started":"2022-06-30T15:32:41.911619Z","shell.execute_reply":"2022-06-30T15:32:41.919390Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"sparse_locations = location_tally[location_tally<=10]\nsparse_locations","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:47.379525Z","iopub.execute_input":"2022-06-30T15:32:47.380228Z","iopub.status.idle":"2022-06-30T15:32:47.390264Z","shell.execute_reply.started":"2022-06-30T15:32:47.380178Z","shell.execute_reply":"2022-06-30T15:32:47.389329Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"markdown","source":"I think it's fair to tie up these sparse locations into one collective variable \"others\"","metadata":{}},{"cell_type":"code","source":"# I'm creating a new location variable \"other\", for all the locations that have less than 10 houses.\ndf4.location = df4.location.apply(lambda x: 'others' if x in sparse_locations else x)\nlen(df4.location.unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:50.010977Z","iopub.execute_input":"2022-06-30T15:32:50.011559Z","iopub.status.idle":"2022-06-30T15:32:50.034246Z","shell.execute_reply.started":"2022-06-30T15:32:50.011515Z","shell.execute_reply":"2022-06-30T15:32:50.033134Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"markdown","source":"The locations are now more concise than earlier.","metadata":{}},{"cell_type":"code","source":"df4.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:52.698334Z","iopub.execute_input":"2022-06-30T15:32:52.698745Z","iopub.status.idle":"2022-06-30T15:32:52.713776Z","shell.execute_reply.started":"2022-06-30T15:32:52.698714Z","shell.execute_reply":"2022-06-30T15:32:52.712732Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"markdown","source":"There are some anomalies in the data where entries have a high bhk value and a low total_sqft<br>\nvalue. For example, the loc(9) of the above dataframe, bhk=6 and total_sqft=1020. <br>\nThe square feet per bhk should be of a certain value that is comprehendable.<br>\nNormally you would ask your real estate manager for a good threshold to use. <br>\nI'll use 320","metadata":{}},{"cell_type":"code","source":"# The entries in the dataset where the quotient of the total_sqft/bhk < 320.\ndf4[df4.total_sqft/df4.bhk<320].head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:55.389995Z","iopub.execute_input":"2022-06-30T15:32:55.390362Z","iopub.status.idle":"2022-06-30T15:32:55.407317Z","shell.execute_reply.started":"2022-06-30T15:32:55.390333Z","shell.execute_reply":"2022-06-30T15:32:55.405790Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"markdown","source":"## Outlier filtering","metadata":{}},{"cell_type":"code","source":"# I create a new dataframe where I filter entries that have a (total_sqft/bhk) < 320 .\ndf5 = df4[~(df4.total_sqft/df4.bhk<300)]\ndf5.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:57.970779Z","iopub.execute_input":"2022-06-30T15:32:57.971192Z","iopub.status.idle":"2022-06-30T15:32:57.982178Z","shell.execute_reply.started":"2022-06-30T15:32:57.971163Z","shell.execute_reply":"2022-06-30T15:32:57.981001Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"# Some statistical info about the price_per_sqft column.\ndf5.price_per_sqft.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:32:59.158122Z","iopub.execute_input":"2022-06-30T15:32:59.159506Z","iopub.status.idle":"2022-06-30T15:32:59.171486Z","shell.execute_reply.started":"2022-06-30T15:32:59.159450Z","shell.execute_reply":"2022-06-30T15:32:59.170599Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"From the above we can see that there are houses that are overly cheap(min) and some that are<br> overly expensive(max). Since I'm trying to build a generic model that will serve the larger majority,<br>it will be fair to get rid of these extreme entries (outliers).","metadata":{}},{"cell_type":"code","source":"# I'll create a function that filters out overly expensive and overly cheap houses.\ndef filter_outliers1(dataframe):\n    ''' \n        This function takes the dataframe, and groupby the location.\n\n        For each location, we calculate the mean and standard deviation of the \n        price_per_sqft in that location.\n\n        Then we use the mean and standard deviation to filter entries that lie beyond some \n        specified threshold.\n    '''\n    df = pd.DataFrame()\n    for location, minidf in dataframe.groupby('location'):\n        mean = np.mean(minidf.price_per_sqft)\n        std = np.std(minidf.price_per_sqft)\n        filtered_df = minidf[(minidf.price_per_sqft>(mean-std)) & (minidf.price_per_sqft<=(mean+std))]\n        df = pd.concat([df, filtered_df], ignore_index=True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:33:01.650348Z","iopub.execute_input":"2022-06-30T15:33:01.651368Z","iopub.status.idle":"2022-06-30T15:33:01.660307Z","shell.execute_reply.started":"2022-06-30T15:33:01.651320Z","shell.execute_reply":"2022-06-30T15:33:01.659165Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"df6 = filter_outliers1(df5)\ndf6.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:33:03.270694Z","iopub.execute_input":"2022-06-30T15:33:03.272022Z","iopub.status.idle":"2022-06-30T15:33:03.750092Z","shell.execute_reply.started":"2022-06-30T15:33:03.271975Z","shell.execute_reply":"2022-06-30T15:33:03.748971Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"markdown","source":"We got rid of quite some entries there.","metadata":{}},{"cell_type":"code","source":"# Number of house in each bhk size.\ndf6.groupby('bhk')['bhk'].agg('count')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:33:05.938474Z","iopub.execute_input":"2022-06-30T15:33:05.939386Z","iopub.status.idle":"2022-06-30T15:33:05.949003Z","shell.execute_reply.started":"2022-06-30T15:33:05.939349Z","shell.execute_reply":"2022-06-30T15:33:05.947602Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"markdown","source":"Apparently, most houses have 2 or 3 bhk.","metadata":{}},{"cell_type":"code","source":"# Let's see how the prices of 2 bhk and 3 bhk vary in the same location.\ndef scatter_plot(dataframe, location):\n    bhk2 = dataframe[(dataframe.location==location) & (dataframe.bhk==2)]\n    bhk3 = dataframe[(dataframe.location==location) & (dataframe.bhk==3)]\n    plt.scatter(bhk2.total_sqft, bhk2.price, color='cyan', label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft, bhk3.price, marker='+', color='pink', label='3 BHK', s=50)\n    plt.xlabel('Total square feet area')\n    plt.ylabel('Price per square feet')\n    plt.title(f'Price comparison of houses in {location} with 2 or 3 bedrooms')\n    plt.legend()\n\nscatter_plot(df6, 'Marathahalli')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:33:07.851337Z","iopub.execute_input":"2022-06-30T15:33:07.852787Z","iopub.status.idle":"2022-06-30T15:33:08.036102Z","shell.execute_reply.started":"2022-06-30T15:33:07.852729Z","shell.execute_reply":"2022-06-30T15:33:08.034736Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"See how some 3 bhk houses cost less than 2 bhk houses with the same total square feet area.<br>\nNormally you'll think that, in the same location, for more bhk, the price of a given house should<br>cost more than one with less bhk, provided the square feet area is fairly same.\n<br>\nSo I'll go ahead and write a function that filters these outliers.","metadata":{}},{"cell_type":"code","source":"def filter_outliers2(dataframe):\n    '''First, I create an array of indices of the outliers to filter/remove; filter_indices.\n       \n       Second, I group the dataframe by location; location_df\n       \n       Third, I create an empty dictionary 'bhk_info', and then group 'location_df' by 'bhk'\n       \n       Fourth, I get the mean and standard deviation of the price per square feet of all the\n       house with a particular bhk, and in the same Location. Also the count of the houses.\n       \n       Finally, I'll pass the stats info to the dictionary and use the information in this\n       bhk_info dictionary to get the indices of the entries where the price per square feet\n       of a given house, in a given location with more bhk, is less than that of a house \n       with less bhk.\n      '''\n    filter_indices = np.array([])\n    for location, location_df in dataframe.groupby('location'):\n        bhk_info = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_info[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            info = bhk_info.get(bhk-1)\n            if info and info['count']>5: # Only ones greater than 5.\n                filter_indices = np.append(filter_indices, \n                             bhk_df[bhk_df.price_per_sqft<(info['mean'])].index.values)\n    return dataframe.drop(filter_indices, axis='index')\n\ndf7 = filter_outliers2(df6)\ndf7.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:33:10.413039Z","iopub.execute_input":"2022-06-30T15:33:10.413475Z","iopub.status.idle":"2022-06-30T15:33:11.264973Z","shell.execute_reply.started":"2022-06-30T15:33:10.413443Z","shell.execute_reply":"2022-06-30T15:33:11.263732Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"# I'd run the scatter plot function again to see how well we did with filtering the outlier. \nscatter_plot(df7, 'Marathahalli')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:33:13.250374Z","iopub.execute_input":"2022-06-30T15:33:13.250851Z","iopub.status.idle":"2022-06-30T15:33:13.451187Z","shell.execute_reply.started":"2022-06-30T15:33:13.250814Z","shell.execute_reply":"2022-06-30T15:33:13.449750Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"We succeeded in filtering those outliers.<br>\nLets see the bath columns, there might be a few outliers in that column.","metadata":{}},{"cell_type":"code","source":"df7.bath.unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:36:12.905126Z","iopub.execute_input":"2022-06-30T15:36:12.905540Z","iopub.status.idle":"2022-06-30T15:36:12.914990Z","shell.execute_reply.started":"2022-06-30T15:36:12.905509Z","shell.execute_reply":"2022-06-30T15:36:12.913540Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# The entries in the dataset where bath is greater than 9.\ndf7[df7.bath>9]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:36:52.316003Z","iopub.execute_input":"2022-06-30T15:36:52.316458Z","iopub.status.idle":"2022-06-30T15:36:52.333612Z","shell.execute_reply.started":"2022-06-30T15:36:52.316426Z","shell.execute_reply":"2022-06-30T15:36:52.332429Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"# I'll use a histogtram to see the most common number of bathrooms in the dataset.\nplt.hist(df7.bath, rwidth=.7)\nplt.xlabel('Number of bathrooms')\nplt.ylabel('Counts')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:36:55.922837Z","iopub.execute_input":"2022-06-30T15:36:55.923247Z","iopub.status.idle":"2022-06-30T15:36:56.087165Z","shell.execute_reply.started":"2022-06-30T15:36:55.923216Z","shell.execute_reply":"2022-06-30T15:36:56.086380Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"markdown","source":"Now there are some houses that have an usual number of bathrooms. Let's check them out.","metadata":{}},{"cell_type":"code","source":"# Entries in the dataset where the number of bathrooms is more than the bhk+2.\ndf7[df7.bath>df7.bhk+2]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:22.706343Z","iopub.execute_input":"2022-06-30T15:37:22.707843Z","iopub.status.idle":"2022-06-30T15:37:22.729322Z","shell.execute_reply.started":"2022-06-30T15:37:22.707786Z","shell.execute_reply":"2022-06-30T15:37:22.728120Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"# I create a new dataframe where the number of the bathroom is not more than \n# the bhk+2(prefered threshold).\ndf8 = df7[df7.bath<df7.bhk+2]\ndf8.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:23.826345Z","iopub.execute_input":"2022-06-30T15:37:23.827906Z","iopub.status.idle":"2022-06-30T15:37:23.837809Z","shell.execute_reply.started":"2022-06-30T15:37:23.827841Z","shell.execute_reply":"2022-06-30T15:37:23.836287Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"I used the price_per_sqft column to do alot of outlier filtering but I would have to drop<br> it as it won't be an important feature for training the regression model.<br>\nAs well as the size column.","metadata":{}},{"cell_type":"code","source":"df9 = df8.drop(['size', 'price_per_sqft'], axis=1)\ndf9.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:33.147766Z","iopub.execute_input":"2022-06-30T15:37:33.148693Z","iopub.status.idle":"2022-06-30T15:37:33.164298Z","shell.execute_reply.started":"2022-06-30T15:37:33.148632Z","shell.execute_reply":"2022-06-30T15:37:33.163092Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"markdown","source":"There are over 200 locations in the dataset, and they are all string data type.<br>\nMachine learning models don't understand string for the most part, hence<br>\nI will use a one-hot encoding approach facilitated by pd.get_dummies, to create<br>\na new dataframe of zeros and ones that represent the location in a certain way.<br>\nFor example, if the location is 'Electric City', the 'Electric City' column will have a<br> value 1 and every other columns will be zeros.","metadata":{}},{"cell_type":"code","source":"dummies = pd.get_dummies(df9.location)\ndummies.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:35.514124Z","iopub.execute_input":"2022-06-30T15:37:35.515422Z","iopub.status.idle":"2022-06-30T15:37:35.547751Z","shell.execute_reply.started":"2022-06-30T15:37:35.515366Z","shell.execute_reply":"2022-06-30T15:37:35.546400Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# We concatenate our dummies-dataframe to out main dataframe.\ndf10 = pd.concat([df9, dummies.drop('others', axis=1)], axis=1)\ndf10.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:36.643129Z","iopub.execute_input":"2022-06-30T15:37:36.643527Z","iopub.status.idle":"2022-06-30T15:37:36.674444Z","shell.execute_reply.started":"2022-06-30T15:37:36.643498Z","shell.execute_reply":"2022-06-30T15:37:36.673258Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"I dropped the 'others' column to prevent the dummy variable trap. <br>\nSo when all the columns are zero then it will entail 'others' location.","metadata":{}},{"cell_type":"code","source":"# Create a new dataframe and drop the location column as it isn't needed any longer. \ndf11 = df10.drop(['location'], axis=1)\ndf11.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:41.947007Z","iopub.execute_input":"2022-06-30T15:37:41.947836Z","iopub.status.idle":"2022-06-30T15:37:41.976232Z","shell.execute_reply.started":"2022-06-30T15:37:41.947786Z","shell.execute_reply":"2022-06-30T15:37:41.974778Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"df11.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:43.406086Z","iopub.execute_input":"2022-06-30T15:37:43.407386Z","iopub.status.idle":"2022-06-30T15:37:43.413707Z","shell.execute_reply.started":"2022-06-30T15:37:43.407343Z","shell.execute_reply":"2022-06-30T15:37:43.412470Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"# Create a feature variable 'X', which holds the data for prediction with 'price' dropped.\nX = df11.drop('price', axis=1)\nX","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:45.144855Z","iopub.execute_input":"2022-06-30T15:37:45.145309Z","iopub.status.idle":"2022-06-30T15:37:45.173119Z","shell.execute_reply.started":"2022-06-30T15:37:45.145276Z","shell.execute_reply":"2022-06-30T15:37:45.172186Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"# We create the targets variable 'Y' which holds the price.\nY = df11.price\nY","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:47.266618Z","iopub.execute_input":"2022-06-30T15:37:47.267305Z","iopub.status.idle":"2022-06-30T15:37:47.277641Z","shell.execute_reply.started":"2022-06-30T15:37:47.267259Z","shell.execute_reply":"2022-06-30T15:37:47.276449Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# We'll split the data into training and testing chunks using train_test_split.\nfrom sklearn.model_selection import train_test_split as tts\nX_train, X_test, Y_train, Y_test = tts(X, Y, test_size=.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:37:54.806096Z","iopub.execute_input":"2022-06-30T15:37:54.806950Z","iopub.status.idle":"2022-06-30T15:37:55.293183Z","shell.execute_reply.started":"2022-06-30T15:37:54.806908Z","shell.execute_reply":"2022-06-30T15:37:55.291712Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nclf = LinearRegression()\nclf.fit(X_train.values, Y_train.values) # Training step!\naccuracy = (clf.score(X_test.values, Y_test.values))*100 \nprint(f'Accuracy of the model: {(accuracy):.1f}%')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:38:08.348267Z","iopub.execute_input":"2022-06-30T15:38:08.352079Z","iopub.status.idle":"2022-06-30T15:38:08.617603Z","shell.execute_reply.started":"2022-06-30T15:38:08.352010Z","shell.execute_reply":"2022-06-30T15:38:08.614479Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"# I've implemented a function that uses the model to predict price.\ndef predictPrice(location, sqft, bath, bhk):\n    loc_index = np.where(X.columns==location)[0][0]  # Get index of the location passed\n    x = np.zeros(len(X.columns)) # Create an array of zeros\n    x[0] = sqft  # assign sqft as the first input\n    x[1] = bath # assign bath as the second input\n    x[2] = bhk  # assign bhk as the third input\n    if loc_index > 0:\n        x[loc_index] = 1 # assign 1 wherever the location should be in the array.\n    return clf.predict([x])[0] ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:38:52.668245Z","iopub.execute_input":"2022-06-30T15:38:52.669450Z","iopub.status.idle":"2022-06-30T15:38:52.676259Z","shell.execute_reply.started":"2022-06-30T15:38:52.669405Z","shell.execute_reply":"2022-06-30T15:38:52.675120Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"markdown","source":"Note: The arrangement of the values in the __x__ is very important because that's<br>\nthe structure of the data when we were training the model.","metadata":{}},{"cell_type":"code","source":"price = predictPrice('1st Block Jayanagar', 2000, 4, 5)\nprint(f\"Price: {price:.2f}Lakh\")","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:40:10.498835Z","iopub.execute_input":"2022-06-30T15:40:10.499489Z","iopub.status.idle":"2022-06-30T15:40:10.507856Z","shell.execute_reply.started":"2022-06-30T15:40:10.499449Z","shell.execute_reply":"2022-06-30T15:40:10.506451Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"price = predictPrice('Electronic City', 1200, 4, 4)\nprint(f\"Price: {price:.2f}Lakh\")","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:40:36.857859Z","iopub.execute_input":"2022-06-30T15:40:36.858293Z","iopub.status.idle":"2022-06-30T15:40:36.866934Z","shell.execute_reply.started":"2022-06-30T15:40:36.858261Z","shell.execute_reply":"2022-06-30T15:40:36.865490Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"price = predictPrice('2nd Stage Nagarbhavi', 900, 2, 3)\nprint(f\"Price: {price:.2f}Lakh\")","metadata":{"execution":{"iopub.status.busy":"2022-06-30T15:40:53.617098Z","iopub.execute_input":"2022-06-30T15:40:53.617478Z","iopub.status.idle":"2022-06-30T15:40:53.624216Z","shell.execute_reply.started":"2022-06-30T15:40:53.617450Z","shell.execute_reply":"2022-06-30T15:40:53.622768Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"markdown","source":"Clearly, houses appear to be more expensive in some locations and cheaper in some too. <br>\nAnd the model picked that too.","metadata":{}},{"cell_type":"code","source":"# ifunanyaScript","metadata":{},"execution_count":null,"outputs":[]}]}